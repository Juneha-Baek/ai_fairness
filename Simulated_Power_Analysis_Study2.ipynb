{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb7bde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import logit\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def generate_candidate_pair_data(n_pairs):\n",
    "    \"\"\"\n",
    "    Generate realistic paired comparison data based on actual hiring statistics\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_pairs : int\n",
    "        Number of candidate pairs\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    List of candidate pairs with attribute differences\n",
    "    \"\"\"\n",
    "    \n",
    "    pairs = []\n",
    "    \n",
    "    for pair_id in range(n_pairs):\n",
    "        # Generate two candidates based on actual hiring data distributions\n",
    "        candidates = []\n",
    "        \n",
    "        for candidate_num in range(2):\n",
    "            # Basic demographics (from summary stats)\n",
    "            female = np.random.binomial(1, 0.5)\n",
    "            \n",
    "            # Internship experience\n",
    "            internship_exp = np.random.binomial(1, 0.483)\n",
    "            \n",
    "            # Certificates (0-4, following actual distribution)\n",
    "            certificates = np.random.choice(range(5), p=[0.1, 0.25, 0.25, 0.25, 0.15])\n",
    "            \n",
    "            # University ranking (simplified to numeric for easier difference calculation)\n",
    "            university_values = {\n",
    "                'etc': 0,  # baseline\n",
    "                'domestic_top14_22': 0.897,\n",
    "                'international_middle_low': 1.136,\n",
    "                'domestic_top10_13': 1.309,\n",
    "                'domestic_top9_female': 1.400,\n",
    "                'domestic_top6_8': 1.881,\n",
    "                'domestic_top4_5': 2.348,\n",
    "                'international_high': 2.525,\n",
    "                'domestic_top3': 3.525\n",
    "            }\n",
    "            university_categories = list(university_values.keys())\n",
    "            university_probs = [0.35, 0.05, 0.02, 0.18, 0.02, 0.15, 0.12, 0.03, 0.08]\n",
    "            university_cat = np.random.choice(university_categories, p=university_probs)\n",
    "            university_score = university_values[university_cat]\n",
    "            \n",
    "            # GPA (from summary stats, no quadratic term)\n",
    "            gpa = np.random.normal(80.934, 7.489)\n",
    "            gpa = np.clip(gpa, 36.4, 100.0)\n",
    "            \n",
    "            candidates.append({\n",
    "                'female': female,\n",
    "                'internship_exp': internship_exp,\n",
    "                'certificates': certificates,\n",
    "                'university_score': university_score,\n",
    "                'gpa': gpa\n",
    "            })\n",
    "        \n",
    "        # Calculate differences (Candidate 1 - Candidate 2)\n",
    "        delta_gender = (1 - candidates[0]['female']) - (1 - candidates[1]['female'])  # male=1, female=0\n",
    "        delta_internship_exp = candidates[0]['internship_exp'] - candidates[1]['internship_exp']\n",
    "        delta_certificates = candidates[0]['certificates'] - candidates[1]['certificates']\n",
    "        delta_university = candidates[0]['university_score'] - candidates[1]['university_score']\n",
    "        delta_gpa = candidates[0]['gpa'] - candidates[1]['gpa']\n",
    "        \n",
    "        pairs.append({\n",
    "            'pair_id': pair_id,\n",
    "            'delta_gender': delta_gender,\n",
    "            'delta_internship_exp': delta_internship_exp,\n",
    "            'delta_certificates': delta_certificates,\n",
    "            'delta_university': delta_university,\n",
    "            'delta_gpa': delta_gpa,\n",
    "            'candidate1': candidates[0],\n",
    "            'candidate2': candidates[1]\n",
    "        })\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "def create_balanced_groups_with_responsibility(n_participants):\n",
    "    \"\"\"\n",
    "    Create balanced groups with proper 2x2 design (AI × Responsibility)\n",
    "    Fixed to create balanced 2x2 design with equal allocation to all 4 conditions\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_participants : int\n",
    "        Total number of participants (must be multiple of 12)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    List of groups with balanced AI and responsibility assignment\n",
    "    \"\"\"\n",
    "    if n_participants % 12 != 0:\n",
    "        raise ValueError(\"Number of participants must be multiple of 12 for balanced design\")\n",
    "    \n",
    "    n_groups = n_participants // 3\n",
    "    \n",
    "    # Ensure we can create balanced 2x2 design\n",
    "    if n_groups % 4 != 0:\n",
    "        raise ValueError(\"Number of groups must be multiple of 4 for balanced 2x2 design\")\n",
    "    \n",
    "    groups_per_condition = n_groups // 4  # 25% each condition\n",
    "    \n",
    "    # Generate participants with balanced gender (50-50)\n",
    "    participants = []\n",
    "    for i in range(n_participants):\n",
    "        participants.append({\n",
    "            'participant_id': i,\n",
    "            'gender': i % 2,  # 0=male, 1=female, alternating for balance\n",
    "        })\n",
    "    \n",
    "    # Separate by gender\n",
    "    males = [p for p in participants if p['gender'] == 0]\n",
    "    females = [p for p in participants if p['gender'] == 1]\n",
    "    \n",
    "    # Shuffle for randomization\n",
    "    np.random.shuffle(males)\n",
    "    np.random.shuffle(females)\n",
    "    \n",
    "    # Create 4 types of groups with equal proportions (25% each)\n",
    "    compositions = [\n",
    "        ('MMM', 3, 0),   # 3 males, 0 females - homogeneous\n",
    "        ('MMF', 2, 1),   # 2 males, 1 female - mixed\n",
    "        ('MFF', 1, 2),   # 1 male, 2 females - mixed  \n",
    "        ('FFF', 0, 3)    # 0 males, 3 females - homogeneous\n",
    "    ]\n",
    "    \n",
    "    groups = []\n",
    "    male_idx = 0\n",
    "    female_idx = 0\n",
    "    group_id = 0\n",
    "    \n",
    "    # Create 2x2 conditions: AI (Yes/No) × Responsibility (High/Low)\n",
    "    conditions = [\n",
    "        (True, True),    # AI=1, High_Resp=1\n",
    "        (True, False),   # AI=1, High_Resp=0  \n",
    "        (False, True),   # AI=0, High_Resp=1\n",
    "        (False, False)   # AI=0, High_Resp=0\n",
    "    ]\n",
    "    \n",
    "    # For each composition type (MMM, MMF, MFF, FFF)\n",
    "    for comp_name, n_males, n_females in compositions:\n",
    "        groups_per_comp = groups_per_condition  # Equal groups per composition\n",
    "        \n",
    "        # Within each composition, assign groups to 4 conditions equally\n",
    "        condition_idx = 0\n",
    "        for _ in range(groups_per_comp):\n",
    "            group_members = []\n",
    "            \n",
    "            # Add required males\n",
    "            for _ in range(n_males):\n",
    "                if male_idx < len(males):\n",
    "                    group_members.append(males[male_idx])\n",
    "                    male_idx += 1\n",
    "            \n",
    "            # Add required females  \n",
    "            for _ in range(n_females):\n",
    "                if female_idx < len(females):\n",
    "                    group_members.append(females[female_idx])\n",
    "                    female_idx += 1\n",
    "            \n",
    "            # Assign to current condition\n",
    "            group_has_ai, group_high_responsibility = conditions[condition_idx]\n",
    "            condition_idx = (condition_idx + 1) % 4  # Cycle through conditions\n",
    "            \n",
    "            # Determine if group is mixed or homogeneous\n",
    "            is_mixed = comp_name in ['MMF', 'MFF']\n",
    "            composition_type = 'mixed' if is_mixed else 'homogeneous'\n",
    "            \n",
    "            groups.append({\n",
    "                'group_id': group_id,\n",
    "                'members': group_members,\n",
    "                'composition': composition_type,\n",
    "                'composition_detailed': comp_name,\n",
    "                'has_ai': group_has_ai,\n",
    "                'high_responsibility': group_high_responsibility\n",
    "            })\n",
    "            \n",
    "            group_id += 1\n",
    "    \n",
    "    # Shuffle groups to randomize order\n",
    "    np.random.shuffle(groups)\n",
    "    \n",
    "    # Verify balanced assignment\n",
    "    ai_counts = {'AI=1,Resp=1': 0, 'AI=1,Resp=0': 0, 'AI=0,Resp=1': 0, 'AI=0,Resp=0': 0}\n",
    "    for group in groups:\n",
    "        key = f\"AI={'1' if group['has_ai'] else '0'},Resp={'1' if group['high_responsibility'] else '0'}\"\n",
    "        ai_counts[key] += 1\n",
    "    \n",
    "    return groups\n",
    "\n",
    "def calculate_selection_probability(pair_data, has_ai, is_group, group_composition, \n",
    "                                                is_high_responsibility, effect_sizes, random_effect):\n",
    "    \"\"\"\n",
    "    재구성된 확률 계산: Individual vs Group 전체 비교 시 group_reduces_bias 효과 보장\n",
    "    \"\"\"\n",
    "    \n",
    "    # Base coefficients\n",
    "    coefficients = {\n",
    "        'intercept': 0,\n",
    "        'gender': 1.519,  \n",
    "        'internship_exp': 0.360,\n",
    "        'certificates': 0.169,\n",
    "        'university': 1.0,\n",
    "        'gpa': 0.335/10\n",
    "    }\n",
    "    \n",
    "    # Base log odds from attribute differences\n",
    "    log_odds = coefficients['intercept']\n",
    "    log_odds += coefficients['gender'] * pair_data['delta_gender']\n",
    "    log_odds += coefficients['internship_exp'] * pair_data['delta_internship_exp']\n",
    "    log_odds += coefficients['certificates'] * pair_data['delta_certificates']\n",
    "    log_odds += coefficients['university'] * pair_data['delta_university']\n",
    "    log_odds += coefficients['gpa'] * pair_data['delta_gpa']\n",
    "    \n",
    "    # Add random effect\n",
    "    log_odds += random_effect\n",
    "    \n",
    "    if is_group:\n",
    "        # ===== 핵심 변경: 모든 그룹의 평균 효과가 group_reduces_bias가 되도록 구성 =====\n",
    "        \n",
    "        # 1. 기본 그룹 효과 (모든 그룹 조건의 중심점)\n",
    "        base_group_effect = effect_sizes['group_reduces_bias']\n",
    "        log_odds += base_group_effect * pair_data['delta_gender']\n",
    "        \n",
    "        # 2. 각 조건별 추가/차감 효과 (평균이 0이 되도록 설계)\n",
    "        \n",
    "        # AI 효과 (AI 그룹은 +, No AI 그룹은 -)\n",
    "        if has_ai:\n",
    "            log_odds += effect_sizes['ai_additional_effect'] * pair_data['delta_gender']\n",
    "        else:\n",
    "            log_odds += (-effect_sizes['ai_additional_effect']) * pair_data['delta_gender']\n",
    "        \n",
    "        # 그룹 구성 효과 (Mixed는 +, Homogeneous는 -)  \n",
    "        if group_composition == 'mixed':\n",
    "            log_odds += effect_sizes['mixed_additional_effect'] * pair_data['delta_gender']\n",
    "        else:  # homogeneous\n",
    "            log_odds += (-effect_sizes['mixed_additional_effect']) * pair_data['delta_gender']\n",
    "        \n",
    "        # 책임감 효과 (High는 +, Low는 -)\n",
    "        if is_high_responsibility:\n",
    "            log_odds += effect_sizes['responsibility_additional_effect'] * pair_data['delta_gender']\n",
    "        else:\n",
    "            log_odds += (-effect_sizes['responsibility_additional_effect']) * pair_data['delta_gender']\n",
    "        \n",
    "        # 상호작용 효과들 (여전히 조건부)\n",
    "        if has_ai and group_composition == 'mixed':\n",
    "            log_odds += effect_sizes['mixed_ai_synergy'] * pair_data['delta_gender']\n",
    "        else:\n",
    "            log_odds += (-effect_sizes['mixed_ai_synergy'] * pair_data['delta_gender'])\n",
    "        \n",
    "        if has_ai and is_high_responsibility:\n",
    "            log_odds += effect_sizes['ai_responsibility_synergy'] * pair_data['delta_gender']\n",
    "        else:\n",
    "            log_odds += (-effect_sizes['ai_responsibility_synergy'] * pair_data['delta_gender'])\n",
    "    \n",
    "    # Convert to probability\n",
    "    prob = 1 / (1 + np.exp(-log_odds))\n",
    "    return np.clip(prob, 1e-10, 1-1e-10)\n",
    "\n",
    "\n",
    "def generate_study2_data_with_responsibility(n_participants, pairs_per_participant_indiv, pairs_per_participant_group, effect_sizes):\n",
    "    \"\"\"\n",
    "    Generate data for Study 2 with individual and group phases, with separate decision counts\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_participants : int\n",
    "        Number of participants (must be divisible by 12)\n",
    "    pairs_per_participant_indiv : int\n",
    "        Number of pairs each participant evaluates individually\n",
    "    pairs_per_participant_group : int\n",
    "        Number of pairs each group evaluates together\n",
    "    effect_sizes : dict\n",
    "        Effect size parameters\n",
    "    \"\"\"\n",
    "    data_rows = []\n",
    "    \n",
    "    # Generate candidate pairs for individual phase\n",
    "    individual_pairs = generate_candidate_pair_data(pairs_per_participant_indiv)\n",
    "    \n",
    "    # Generate DIFFERENT candidate pairs for group phase\n",
    "    group_pairs = generate_candidate_pair_data(pairs_per_participant_group)\n",
    "    \n",
    "    # Create balanced groups with responsibility\n",
    "    groups = create_balanced_groups_with_responsibility(n_participants)\n",
    "    \n",
    "    # Create participant info lookup\n",
    "    participant_info = {}\n",
    "    for group in groups:\n",
    "        for member in group['members']:\n",
    "            participant_info[member['participant_id']] = {\n",
    "                'gender': member['gender'],\n",
    "                'has_ai': group['has_ai'],\n",
    "                'group_id': group['group_id'],\n",
    "                'group_composition': group['composition'],\n",
    "                'high_responsibility': group['high_responsibility']\n",
    "            }\n",
    "    \n",
    "    # Generate random effects for participants and groups\n",
    "    # These remain constant across all decisions for the same unit\n",
    "    participant_random_effects = {}\n",
    "    group_random_effects = {}\n",
    "    \n",
    "    # Generate individual random effects (one per participant)\n",
    "    sigma_within = np.pi**2 / 3 \n",
    "    target_icc_indiv = 0.25\n",
    "    target_icc_group = 0.1\n",
    "    sigma_participant_indiv = np.sqrt(target_icc_indiv * sigma_within / (1 - target_icc_indiv)) \n",
    "    sigma_participant_group = np.sqrt(target_icc_group * sigma_within / (1 - target_icc_group)) \n",
    "\n",
    "    participant_random_effects = {}\n",
    "    for participant_id in range(n_participants):\n",
    "        participant_random_effects[participant_id] = np.random.normal(0, sigma_participant_indiv)\n",
    "\n",
    "    for group in groups:\n",
    "        group_random_effects[group['group_id']] = np.random.normal(0, sigma_participant_group)\n",
    "    \n",
    "    # Individual phase - each participant evaluates individual_pairs\n",
    "    for participant_id in range(n_participants):\n",
    "        info = participant_info[participant_id]\n",
    "        \n",
    "        for pair in individual_pairs:\n",
    "            prob = calculate_selection_probability(\n",
    "                pair, info['has_ai'], is_group=False, group_composition=None, \n",
    "                is_high_responsibility=None,  # No responsibility in individual phase\n",
    "                effect_sizes=effect_sizes, \n",
    "                random_effect=participant_random_effects[participant_id]  # Use consistent random effect\n",
    "            )\n",
    "            y_individual = np.random.binomial(1, prob)\n",
    "            \n",
    "            data_rows.append({\n",
    "                'participant_id': participant_id,\n",
    "                'pair_id': f\"ind_{pair['pair_id']}\",  # Mark as individual pair\n",
    "                'y': y_individual,\n",
    "                'delta_gender': pair['delta_gender'],\n",
    "                'delta_internship_exp': pair['delta_internship_exp'],\n",
    "                'delta_certificates': pair['delta_certificates'],\n",
    "                'delta_university': pair['delta_university'],\n",
    "                'delta_gpa': pair['delta_gpa'],\n",
    "                'has_ai': info['has_ai'],\n",
    "                'is_group': 0,\n",
    "                'group_composition': 'individual',\n",
    "                'high_responsibility': None,  # No responsibility in individual phase\n",
    "                'participant_gender': info['gender'],\n",
    "                'group_id': info['group_id']\n",
    "            })\n",
    "    \n",
    "    # Group phase - each group evaluates group_pairs (NEW pairs)\n",
    "    for group in groups:\n",
    "        group_members = [member['participant_id'] for member in group['members']]\n",
    "        group_composition = group['composition']\n",
    "        group_has_ai = group['has_ai']\n",
    "        group_high_responsibility = group['high_responsibility']\n",
    "        \n",
    "        # Group decisions on NEW pairs (not the same as individual pairs)\n",
    "        for pair in group_pairs:\n",
    "            # Use group probability model with consistent group random effect\n",
    "            prob = calculate_selection_probability(\n",
    "                pair, group_has_ai, is_group=True, \n",
    "                group_composition=group_composition, \n",
    "                is_high_responsibility=group_high_responsibility,\n",
    "                effect_sizes=effect_sizes,\n",
    "                random_effect=group_random_effects[group['group_id']]  # Use consistent group random effect\n",
    "            )\n",
    "            y_group = np.random.binomial(1, prob)\n",
    "            \n",
    "            # Add group decision for each member (same decision, different rows for analysis)\n",
    "            for member in group_members:\n",
    "                member_gender = participant_info[member]['gender']\n",
    "                \n",
    "                data_rows.append({\n",
    "                    'participant_id': member,\n",
    "                    'pair_id': f\"grp_{pair['pair_id']}\",  # Mark as group pair\n",
    "                    'y': y_group,\n",
    "                    'delta_gender': pair['delta_gender'],\n",
    "                    'delta_internship_exp': pair['delta_internship_exp'],\n",
    "                    'delta_certificates': pair['delta_certificates'],\n",
    "                    'delta_university': pair['delta_university'],\n",
    "                    'delta_gpa': pair['delta_gpa'],\n",
    "                    'has_ai': group_has_ai,\n",
    "                    'is_group': 1,\n",
    "                    'group_composition': group_composition,\n",
    "                    'high_responsibility': group_high_responsibility,\n",
    "                    'participant_gender': member_gender,\n",
    "                    'group_id': group['group_id']\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(data_rows)\n",
    "\n",
    "def test_hypothesis_h5(df, alpha=0.05):\n",
    "    \"\"\"Test H5: Group decision reduces gender bias\"\"\"\n",
    "    try:\n",
    "        formula = \"\"\"\n",
    "            y ~ delta_gender + delta_internship_exp + delta_certificates + \n",
    "              delta_university + delta_gpa + is_group + \n",
    "              delta_gender:is_group\n",
    "        \"\"\"\n",
    "        \n",
    "        model = logit(formula, data=df).fit(\n",
    "            cov_type='cluster', \n",
    "            cov_kwds={'groups': df['participant_id']},\n",
    "            disp=0, maxiter=100\n",
    "        )\n",
    "        \n",
    "        # Test if group reduces gender bias (negative interaction)\n",
    "        p_val = model.pvalues.get('delta_gender:is_group', 1.0)\n",
    "        return p_val < alpha\n",
    "        \n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def test_hypothesis_h6(df, alpha=0.05):\n",
    "    \"\"\"Test H6: Fair AI reduces gender bias in group decisions\"\"\"\n",
    "    try:\n",
    "        # Restrict to group decisions only\n",
    "        df_group = df[df['is_group'] == 1].copy()\n",
    "        \n",
    "        formula = \"\"\"\n",
    "            y ~ delta_gender + delta_internship_exp + delta_certificates + \n",
    "              delta_university + delta_gpa + has_ai + \n",
    "              delta_gender:has_ai\n",
    "        \"\"\"\n",
    "        \n",
    "        model = logit(formula, data=df_group).fit(\n",
    "            cov_type='cluster', \n",
    "            cov_kwds={'groups': df_group['group_id']},\n",
    "            disp=0, maxiter=100\n",
    "        )\n",
    "        \n",
    "        # Test if AI reduces gender bias in groups (negative interaction)\n",
    "        p_val = model.pvalues.get('delta_gender:has_ai', 1.0)\n",
    "        return p_val < alpha\n",
    "        \n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def test_hypothesis_h7(df, alpha=0.05):\n",
    "    \"\"\"Test H7: Three-way interaction (Group × AI × Gender)\"\"\"\n",
    "    try:\n",
    "        formula = \"\"\"\n",
    "            y ~ delta_gender + delta_internship_exp + delta_certificates + \n",
    "              delta_university + delta_gpa + is_group + has_ai +\n",
    "              delta_gender:is_group + delta_gender:has_ai + is_group:has_ai +\n",
    "              delta_gender:is_group:has_ai\n",
    "        \"\"\"\n",
    "        \n",
    "        model = logit(formula, data=df).fit(\n",
    "            cov_type='cluster', \n",
    "            cov_kwds={'groups': df['participant_id']},\n",
    "            disp=0, maxiter=100\n",
    "        )\n",
    "        \n",
    "        # Test three-way interaction\n",
    "        p_val = model.pvalues.get('delta_gender:is_group:has_ai', 1.0)\n",
    "        return p_val < alpha\n",
    "        \n",
    "    except:\n",
    "        return False   \n",
    "\n",
    "def test_hypothesis_h8(df, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Test H8: Mixed-gender groups exhibit lowest gender bias (compared to homogeneous groups)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Restrict to group decisions only\n",
    "        df_group = df[df['is_group'] == 1].copy()\n",
    "        \n",
    "        # Create dummy for mixed vs homogeneous\n",
    "        df_group['is_mixed'] = (df_group['group_composition'] == 'mixed').astype(int)\n",
    "        \n",
    "        formula = \"\"\"\n",
    "            y ~ delta_gender + delta_internship_exp + delta_certificates + \n",
    "              delta_university + delta_gpa + is_mixed +\n",
    "              delta_gender:is_mixed\n",
    "        \"\"\"        \n",
    "        model = logit(formula, data=df_group).fit(\n",
    "            cov_type='cluster', \n",
    "            cov_kwds={'groups': df_group['group_id']},\n",
    "            disp=0, maxiter=100\n",
    "        )\n",
    "        \n",
    "        # H8: Test if mixed groups have lower bias (negative coefficient for delta_gender:is_mixed)\n",
    "        if 'delta_gender:is_mixed' in model.pvalues:\n",
    "            h8_pval = model.pvalues['delta_gender:is_mixed']  # Fixed: removed is_group\n",
    "            h8_coef = model.params['delta_gender:is_mixed']\n",
    "            return h8_pval < alpha and h8_coef < 0  # Negative = less bias\n",
    "        \n",
    "        return False\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"H8 test failed: {e}\")\n",
    "        return False\n",
    "\n",
    "def test_hypothesis_h9(df, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Test H9: Mixed-gender groups benefit most from AI interventions\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Restrict to group decisions only\n",
    "        df_group = df[df['is_group'] == 1].copy()\n",
    "        \n",
    "        # Create dummy for mixed vs homogeneous\n",
    "        df_group['is_mixed'] = (df_group['group_composition'] == 'mixed').astype(int)\n",
    "        \n",
    "        formula = \"\"\"\n",
    "            y ~ delta_gender + delta_internship_exp + delta_certificates + \n",
    "              delta_university + delta_gpa + has_ai + is_mixed +\n",
    "              delta_gender:is_mixed + delta_gender:has_ai +\n",
    "              delta_gender:is_mixed:has_ai\n",
    "        \"\"\"\n",
    "        \n",
    "        model = logit(formula, data=df_group).fit(\n",
    "            cov_type='cluster', \n",
    "            cov_kwds={'groups': df_group['group_id']},\n",
    "            disp=0, maxiter=100\n",
    "        )\n",
    "        \n",
    "        # H9: Test if mixed groups benefit more from AI (negative three-way interaction)\n",
    "        if 'delta_gender:is_mixed:has_ai' in model.pvalues:\n",
    "            h9_pval = model.pvalues['delta_gender:is_mixed:has_ai']\n",
    "            return h9_pval < alpha\n",
    "        \n",
    "        return False\n",
    "        \n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def test_hypothesis_h10(df, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Test H10: Responsibility sharing moderates AI effectiveness in reducing gender bias\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Restrict to group decisions only\n",
    "        df_group = df[df['is_group'] == 1].copy()\n",
    "        \n",
    "        # Remove rows where high_responsibility is None (shouldn't happen in group phase)\n",
    "        df_group = df_group.dropna(subset=['high_responsibility'])\n",
    "        \n",
    "        if len(df_group) == 0:\n",
    "            return False\n",
    "        \n",
    "        # Convert to numeric\n",
    "        df_group['high_responsibility'] = df_group['high_responsibility'].astype(int)\n",
    "        \n",
    "        formula = \"\"\"\n",
    "            y ~ delta_gender + delta_internship_exp + delta_certificates + \n",
    "              delta_university + delta_gpa + has_ai + high_responsibility +\n",
    "              delta_gender:has_ai + delta_gender:high_responsibility +\n",
    "              delta_gender:has_ai:high_responsibility\n",
    "        \"\"\"\n",
    "        \n",
    "        model = logit(formula, data=df_group).fit(\n",
    "            cov_type='cluster', \n",
    "            cov_kwds={'groups': df_group['group_id']},\n",
    "            disp=0, maxiter=100\n",
    "        )\n",
    "        \n",
    "        # H10: Test if responsibility moderates AI effectiveness (three-way interaction)\n",
    "        if 'delta_gender:has_ai:high_responsibility' in model.pvalues:\n",
    "            h10_pval = model.pvalues['delta_gender:has_ai:high_responsibility']\n",
    "            return h10_pval < alpha\n",
    "        \n",
    "        return False\n",
    "        \n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def simulate_study2_power_analysis_with_h10(n_participants_list, pairs_per_participant_indiv, pairs_per_participant_group, effect_sizes, n_sim=1000, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Power analysis simulation for Study 2 including H10 with separate individual and group decision counts\n",
    "    \"\"\"\n",
    "    \n",
    "    results = {\n",
    "        'n_participants': n_participants_list,\n",
    "        'power_h5': [],  # Group reduces bias\n",
    "        'power_h6': [],  # AI reduces bias in groups\n",
    "        'power_h7': [],  # Three-way interaction\n",
    "        'power_h8': [],  # Mixed groups have lowest bias\n",
    "        'power_h9': [],  # Mixed groups benefit most from AI\n",
    "        'power_h10': [], # Responsibility moderates AI effectiveness\n",
    "        'convergence_failures': [],\n",
    "        'exceptions': []\n",
    "    }\n",
    "    \n",
    "    print(\"Study 2 Power Analysis with H10\")\n",
    "    print(f\"Individual pairs per participant: {pairs_per_participant_indiv}\")\n",
    "    print(f\"Group pairs per group: {pairs_per_participant_group}\")\n",
    "    print(f\"Group size: 3 participants\")\n",
    "    print(\"Testing hypotheses:\")\n",
    "    print(\"  H5: Group decision reduces gender bias\")\n",
    "    print(\"  H6: Fair AI reduces gender bias in group decisions\") \n",
    "    print(\"  H7: Group × AI × Gender three-way interaction\")\n",
    "    print(\"  H8: Mixed-gender groups have lowest bias\")\n",
    "    print(\"  H9: Mixed-gender groups benefit most from AI\")\n",
    "    print(\"  H10: Responsibility sharing moderates AI effectiveness\")\n",
    "    \n",
    "    for n in n_participants_list:\n",
    "        if n % 12 != 0:\n",
    "            print(f\"WARNING: {n} participants cannot form balanced 4-way groups. Adjusting to {n//12*12}\")\n",
    "            n = n // 12 * 12\n",
    "            \n",
    "        n_groups = n // 3\n",
    "        individual_decisions = n * pairs_per_participant_indiv\n",
    "        group_decisions = n_groups * pairs_per_participant_group\n",
    "        total_decisions = individual_decisions + group_decisions\n",
    "        \n",
    "        print(f\"\\nRunning simulation for {n} participants ({n_groups} groups)...\")\n",
    "        print(f\"  Individual decisions: {individual_decisions:,}\")\n",
    "        print(f\"  Group decisions: {group_decisions:,}\")\n",
    "        print(f\"  Total decisions: {total_decisions:,}\")\n",
    "        print(f\"  Group composition: {n_groups//4} groups each of MMM/MMF/MFF/FFF\")\n",
    "        print(f\"  AI condition: {n_groups//2} AI groups, {n_groups//2} no-AI groups\")\n",
    "        print(f\"  Responsibility: {n_groups//2} high-responsibility groups, {n_groups//2} low-responsibility groups\")\n",
    "        \n",
    "        power_counts = {'h5': 0, 'h6': 0, 'h7': 0, 'h8': 0, 'h9': 0, 'h10': 0}\n",
    "        convergence_fails = 0\n",
    "        exceptions = 0\n",
    "        \n",
    "        for sim in tqdm(range(n_sim), desc=f\"n={n}\", leave=False):\n",
    "            try:\n",
    "                # Generate data\n",
    "                df = generate_study2_data_with_responsibility(n, pairs_per_participant_indiv, pairs_per_participant_group, effect_sizes)\n",
    "                \n",
    "                # Convert to float\n",
    "                for col in ['has_ai', 'is_group', 'delta_gender']:\n",
    "                    df[col] = df[col].astype(float)\n",
    "\n",
    "                # Test each hypothesis\n",
    "                if test_hypothesis_h5(df, alpha):\n",
    "                    power_counts['h5'] += 1\n",
    "                    \n",
    "                if test_hypothesis_h6(df, alpha):\n",
    "                    power_counts['h6'] += 1\n",
    "                    \n",
    "                if test_hypothesis_h7(df, alpha):\n",
    "                    power_counts['h7'] += 1\n",
    "                    \n",
    "                if test_hypothesis_h8(df, alpha):\n",
    "                    power_counts['h8'] += 1\n",
    "                    \n",
    "                if test_hypothesis_h9(df, alpha):\n",
    "                    power_counts['h9'] += 1\n",
    "                    \n",
    "                if test_hypothesis_h10(df, alpha):\n",
    "                    power_counts['h10'] += 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                if \"Singular matrix\" in str(e) or \"convergence\" in str(e).lower():\n",
    "                    convergence_fails += 1\n",
    "                else:\n",
    "                    exceptions += 1\n",
    "                continue\n",
    "        \n",
    "        # Calculate power\n",
    "        valid_sims = n_sim - exceptions\n",
    "        \n",
    "        if valid_sims > 0:\n",
    "            results['power_h5'].append(power_counts['h5'] / valid_sims)\n",
    "            results['power_h6'].append(power_counts['h6'] / valid_sims)\n",
    "            results['power_h7'].append(power_counts['h7'] / valid_sims)\n",
    "            results['power_h8'].append(power_counts['h8'] / valid_sims)\n",
    "            results['power_h9'].append(power_counts['h9'] / valid_sims)\n",
    "            results['power_h10'].append(power_counts['h10'] / valid_sims)\n",
    "        else:\n",
    "            results['power_h5'].append(0)\n",
    "            results['power_h6'].append(0)\n",
    "            results['power_h7'].append(0)\n",
    "            results['power_h8'].append(0)\n",
    "            results['power_h9'].append(0)\n",
    "            results['power_h10'].append(0)\n",
    "            \n",
    "        results['convergence_failures'].append(convergence_fails / n_sim)\n",
    "        results['exceptions'].append(exceptions / n_sim)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def plot_study2_power_curves_with_h10(results, pairs_per_participant_indiv, pairs_per_participant_group):\n",
    "    \"\"\"Plot power curves for Study 2 hypotheses including H10\"\"\"\n",
    "    plt.figure(figsize=(20, 16))\n",
    "    \n",
    "    hypotheses = [\n",
    "        ('power_h5', 'H5: Group Reduces Gender Bias', 'blue'),\n",
    "        ('power_h6', 'H6: AI Reduces Bias in Groups', 'green'),\n",
    "        ('power_h7', 'H7: Group × AI × Gender Interaction', 'red'),\n",
    "        ('power_h8', 'H8: Mixed Groups Have Lowest Bias', 'purple'),\n",
    "        ('power_h9', 'H9: Mixed Groups Benefit Most from AI', 'orange'),\n",
    "        ('power_h10', 'H10: Responsibility Moderates AI Effect', 'brown')\n",
    "    ]\n",
    "    \n",
    "    for i, (power_key, title, color) in enumerate(hypotheses):\n",
    "        plt.subplot(2, 3, i+1)\n",
    "        plt.plot(results['n_participants'], results[power_key], 'o-', \n",
    "                linewidth=2, markersize=6, color=color)\n",
    "        plt.axhline(0.8, color='orange', linestyle='--', alpha=0.7, label='Power = 0.8')\n",
    "        plt.axhline(0.95, color='red', linestyle='--', alpha=0.7, label='Power = 0.95')\n",
    "        plt.title(f'{title}\\n(Individual: {pairs_per_participant_indiv}, Group: {pairs_per_participant_group} pairs)', fontsize=11)\n",
    "        plt.xlabel('Number of Participants')\n",
    "        plt.ylabel('Estimated Power')\n",
    "        plt.ylim(0, 1)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def find_study2_sample_requirements_with_h10(results, pairs_per_participant_indiv, pairs_per_participant_group):\n",
    "    \"\"\"Find sample size requirements for Study 2 hypotheses including H10\"\"\"\n",
    "    \n",
    "    hypotheses = [\n",
    "        ('power_h5', 'H5: Group Reduces Gender Bias'),\n",
    "        ('power_h6', 'H6: AI Reduces Bias in Groups'),\n",
    "        ('power_h7', 'H7: Group × AI × Gender Interaction'),\n",
    "        ('power_h8', 'H8: Mixed Groups Have Lowest Bias'),\n",
    "        ('power_h9', 'H9: Mixed Groups Benefit Most from AI'),\n",
    "        ('power_h10', 'H10: Responsibility Moderates AI Effect')\n",
    "    ]\n",
    "    \n",
    "    for target_power in [0.8, 0.95]:\n",
    "        print(f\"\\n=== {target_power*100}% Power Requirements ===\")\n",
    "        \n",
    "        for power_key, hypothesis_name in hypotheses:\n",
    "            found = False\n",
    "            for i, power in enumerate(results[power_key]):\n",
    "                if power >= target_power:\n",
    "                    n_participants = results['n_participants'][i]\n",
    "                    n_groups = n_participants // 3\n",
    "                    individual_decisions = n_participants * pairs_per_participant_indiv\n",
    "                    group_decisions = n_groups * pairs_per_participant_group  \n",
    "                    total_decisions = individual_decisions + group_decisions\n",
    "                    print(f\"{hypothesis_name}: {n_participants} participants \"\n",
    "                          f\"({n_groups} groups, {total_decisions:,} total decisions)\"\n",
    "                          f\" [Individual: {individual_decisions:,}, Group: {group_decisions:,}]\")\n",
    "                    found = True\n",
    "                    break\n",
    "            \n",
    "            if not found:\n",
    "                max_n = max(results['n_participants'])\n",
    "                max_power = max(results[power_key])\n",
    "                max_groups = max_n // 3\n",
    "                max_individual = max_n * pairs_per_participant_indiv\n",
    "                max_group_decisions = max_groups * pairs_per_participant_group\n",
    "                max_total = max_individual + max_group_decisions\n",
    "                print(f\"{hypothesis_name}: >{max_n} participants needed \"\n",
    "                      f\"(max observed power: {max_power:.3f}, would need >{max_total:,} decisions)\")\n",
    "\n",
    "# Example execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Experimental design parameters - NOW SEPARATE\n",
    "    pairs_per_participant_indiv = 10  # Each participant evaluates 10 pairs individually\n",
    "    pairs_per_participant_group = 30   # Each group evaluates 30 pairs together (balances the decision counts)\n",
    "    \n",
    "    participants_range = list(range(60, 301, 60))  # Must be multiples of 12: 240, 360, 480\n",
    "    \n",
    "    # Adjust to multiples of 12 for balanced 4-way design\n",
    "    participants_range = [n for n in participants_range if n % 12 == 0]\n",
    "    if not participants_range:\n",
    "        participants_range = [240, 360, 480]  # All multiples of 12\n",
    "    \n",
    "    # Define effect sizes - Reduced to avoid saturation effects\n",
    "    # Individual effects should be smaller when combined\n",
    "    effect_sizes = {\n",
    "        'group_reduces_bias': -1.451,  # 계산된 기준점\n",
    "        \n",
    "        # 각 조건별 편차 (평균이 0이 되도록 설계)\n",
    "        'ai_additional_effect': -0.542/2,          # \n",
    "        'mixed_additional_effect': -0.542/2,      #  small to medium effect cohed's d = 0.3 \n",
    "        'responsibility_additional_effect': 0,  \n",
    "        \n",
    "        # 상호작용 효과들\n",
    "        'mixed_ai_synergy': -1.451/2,           # Mixed × AI 추가 시너지 large effect\n",
    "        'ai_responsibility_synergy': -1.451/2    # AI × High Responsibility 추가 시너지\n",
    "    }\n",
    "\n",
    "    \n",
    "    print(\"=== STUDY 2 POWER ANALYSIS WITH H10 (BALANCED 4-WAY DESIGN) ===\")\n",
    "    print(f\"Participants range: {participants_range} (multiples of 12)\")\n",
    "    print(f\"Individual pairs per participant: {pairs_per_participant_indiv}\")\n",
    "    print(f\"Group pairs per group: {pairs_per_participant_group}\")\n",
    "    print(f\"Group composition: 25% each of MMM/MMF/MFF/FFF\")\n",
    "    print(f\"  - Homogeneous groups: MMM + FFF (50%)\")\n",
    "    print(f\"  - Mixed groups: MMF + MFF (50%)\")\n",
    "    print(f\"AI condition: 50% groups AI, 50% groups no-AI\")\n",
    "    print(f\"Responsibility condition: 50% groups high, 50% groups low\")\n",
    "    print(\"Effect sizes:\")\n",
    "    for key, value in effect_sizes.items():\n",
    "        print(f\"  {key}: {value:.3f}\")\n",
    "    print(\"\\nHypotheses:\")\n",
    "    print(\"  H5: Group decision reduces gender bias\")\n",
    "    print(\"  H6: Fair AI reduces gender bias in group decisions\")\n",
    "    print(\"  H7: Group × AI × Gender three-way interaction\")\n",
    "    print(\"  H8: Mixed-gender groups exhibit lowest levels of gender bias\")\n",
    "    print(\"  H9: Mixed-gender groups benefit most from fair AI interventions\")\n",
    "    print(\"  H10: High responsibility groups benefit more from AI than low responsibility groups\")\n",
    "    \n",
    "    # Run power analysis\n",
    "    results = simulate_study2_power_analysis_with_h10(\n",
    "        n_participants_list=participants_range,\n",
    "        pairs_per_participant_indiv=pairs_per_participant_indiv,\n",
    "        pairs_per_participant_group=pairs_per_participant_group,\n",
    "        effect_sizes=effect_sizes,\n",
    "        n_sim=1000,\n",
    "        alpha=0.05\n",
    "    )\n",
    "    \n",
    "    # Plot results\n",
    "    plot_study2_power_curves_with_h10(results, pairs_per_participant_indiv, pairs_per_participant_group)\n",
    "    \n",
    "    # Find sample size requirements\n",
    "    find_study2_sample_requirements_with_h10(results, pairs_per_participant_indiv, pairs_per_participant_group)\n",
    "    \n",
    "    # Print detailed results\n",
    "    print(f\"\\n=== DETAILED RESULTS ===\")\n",
    "    for i, n in enumerate(results['n_participants']):\n",
    "        n_groups = n // 3\n",
    "        individual_decisions = n * pairs_per_participant_indiv\n",
    "        group_decisions = n_groups * pairs_per_participant_group\n",
    "        total_decisions = individual_decisions + group_decisions\n",
    "        print(f\"n={n:3d} ({n_groups:2d} groups, {total_decisions:4d} decisions): \"\n",
    "              f\"H5={results['power_h5'][i]:.3f}, \"\n",
    "              f\"H6={results['power_h6'][i]:.3f}, \"\n",
    "              f\"H7={results['power_h7'][i]:.3f}, \"\n",
    "              f\"H8={results['power_h8'][i]:.3f}, \"\n",
    "              f\"H9={results['power_h9'][i]:.3f}, \"\n",
    "              f\"H10={results['power_h10'][i]:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diversity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
